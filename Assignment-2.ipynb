{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9d01543-6a4e-4580-98ab-1f7af89ffd92",
   "metadata": {},
   "source": [
    "# ASSIGNMENT 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c43026-8e75-4adf-926b-91259d9ac884",
   "metadata": {},
   "source": [
    "## Chin Wai Yee - Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c758d8c1-11e6-44d7-b3d4-03e6e21f2ceb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T09:07:10.686837Z",
     "iopub.status.busy": "2025-05-02T09:07:10.686339Z",
     "iopub.status.idle": "2025-05-02T09:07:20.799358Z",
     "shell.execute_reply": "2025-05-02T09:07:20.798797Z",
     "shell.execute_reply.started": "2025-05-02T09:07:10.686818Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import kagglehub\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"tristanzhang32/ai-generated-images-vs-real-images\")\n",
    "\n",
    "ai_dir = path + \"/train/fake\"\n",
    "real_dir = path + \"/train/real\"\n",
    "\n",
    "# Label 0 = AI-generated, Label 1 = Real\n",
    "ai_data = [(os.path.join(ai_dir, f), 0) for f in os.listdir(ai_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "real_data = [(os.path.join(real_dir, f), 1) for f in os.listdir(real_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "full_data = ai_data + real_data\n",
    "labels = [label for _, label in full_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c94a32b-99b8-4c20-bf91-16475da6a68e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T09:07:20.800455Z",
     "iopub.status.busy": "2025-05-02T09:07:20.800057Z",
     "iopub.status.idle": "2025-05-02T09:07:20.857711Z",
     "shell.execute_reply": "2025-05-02T09:07:20.857031Z",
     "shell.execute_reply.started": "2025-05-02T09:07:20.800434Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train/val/test split\n",
    "train_val_data, test_data = train_test_split(full_data, test_size=0.15, stratify=labels, random_state=42)\n",
    "train_data, val_data = train_test_split(train_val_data, test_size=0.15, stratify=[label for _, label in train_val_data], random_state=42)\n",
    "\n",
    "# Custom Dataset\n",
    "class ImagePathDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path)\n",
    "    \n",
    "            if image.mode == 'P':\n",
    "                image = image.convert('RGBA')\n",
    "                background = Image.new(\"RGB\", image.size, (255, 255, 255))\n",
    "                image = Image.alpha_composite(background.convert('RGBA'), image).convert('RGB')\n",
    "            else:\n",
    "                image = image.convert('RGB')\n",
    "    \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, label\n",
    "    \n",
    "        except (OSError, IOError) as e:\n",
    "            print(f\"Skipping corrupted image: {img_path} ({str(e)})\")\n",
    "            return self.__getitem__((idx + 1) % len(self.data))  # Try next image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ffa2f49-02a6-4823-b049-2660dae2d3bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T09:07:20.859370Z",
     "iopub.status.busy": "2025-05-02T09:07:20.859167Z",
     "iopub.status.idle": "2025-05-02T09:07:20.864439Z",
     "shell.execute_reply": "2025-05-02T09:07:20.863749Z",
     "shell.execute_reply.started": "2025-05-02T09:07:20.859355Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data Augmentation for training\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# Standard transform for val/test\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aed2b12-9acf-496e-9ad3-8ccf3fa71dc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T09:07:20.865339Z",
     "iopub.status.busy": "2025-05-02T09:07:20.865089Z",
     "iopub.status.idle": "2025-05-02T09:07:20.884308Z",
     "shell.execute_reply": "2025-05-02T09:07:20.883729Z",
     "shell.execute_reply.started": "2025-05-02T09:07:20.865317Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create datasets and loaders\n",
    "train_dataset = ImagePathDataset(train_data, transform=train_transform)\n",
    "val_dataset = ImagePathDataset(val_data, transform=test_transform)\n",
    "test_dataset = ImagePathDataset(test_data, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9b4133-6c70-425b-9a4d-ed9a06e7414e",
   "metadata": {},
   "source": [
    "## Loh Kin Ming - Model, Hyperparameters & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30ea76b-c0d0-4107-8667-eb6d1e62b19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfff48c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=2)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da830c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To Freeze Layers\n",
    "## Uncomment below to run\n",
    "# Freeze all layers\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# # Unfreeze only the classifier\n",
    "# for param in model.classifier.parameters():\n",
    "#     param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8890c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8adaa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        correct, total = 0, 0\n",
    "        \n",
    "        for images, labels in tqdm(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        acc = correct / total * 100\n",
    "        print(f\"Epoch {epoch+1}: Loss={running_loss:.4f}, Accuracy={acc:.2f}%\")\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        evaluate(model, val_loader, \"Validation\")\n",
    "\n",
    "def evaluate(model, loader, name=\"Test\"):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    print(f\"{name} Accuracy: {correct / total * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795d55be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, train_loader, val_loader, epochs=5)\n",
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ab31f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the full model\n",
    "torch.save(model, \"model_full.pth\")\n",
    "\n",
    "# Download the model file to local device\n",
    "from IPython.display import FileLink\n",
    "\n",
    "FileLink('model_full.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631099e1-24c0-41ff-b3ac-3d95e5e11afc",
   "metadata": {},
   "source": [
    "## Brandon Ting En Junn - Evaluation & Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfce766-f5f0-4719-9ad0-6e5a6edf7fe1",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision.models import efficientnet_b0\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve, roc_auc_score, roc_curve, cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a117d39-d8ed-4f17-ba0c-5eff48f796df",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ModelEvaluator():\n",
    "    def __init__(self, model, data_loader):\n",
    "        self.model = model\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.y_true = []\n",
    "        self.y_pred = []\n",
    "        self.y_score = []\n",
    "\n",
    "        self.model.eval()\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        print(\"Running Evaluation...\")\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in data_loader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                probits = torch.softmax(outputs, dim=1)\n",
    "\n",
    "                _, pred = torch.max(probits, dim=1)\n",
    "\n",
    "                self.y_true.extend(labels.to(\"cpu\").numpy())\n",
    "                self.y_pred.extend(pred.to(\"cpu\").numpy())\n",
    "                self.y_score.extend(probits[:, 1].to(\"cpu\").numpy())\n",
    "        print(\"Finished Evaluation...\")\n",
    "\n",
    "    def confusion_matrix(self):\n",
    "        sns.heatmap(confusion_matrix(self.y_true, self.y_pred), annot=True)\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.show()\n",
    "\n",
    "    def accuracy(self):\n",
    "        print(f\"Accuracy: {accuracy_score(self.y_true, self.y_pred)}\")\n",
    "\n",
    "    def precision(self):\n",
    "        print(f\"Precision: {precision_score(self.y_true, self.y_pred)}\")\n",
    "\n",
    "    def recall(self):\n",
    "        print(f\"Recall: {recall_score(self.y_true, self.y_pred)}\")\n",
    "\n",
    "    def f1_score(self):\n",
    "        print(f\"F1-Score: {f1_score(self.y_true, self.y_pred)}\")\n",
    "\n",
    "    def kappa(self):\n",
    "        print(f\"Kappa Coefficient: {cohen_kappa_score(self.y_true, self.y_pred)}\")\n",
    "\n",
    "    def precision_recall_curve(self):\n",
    "        precision, recall, _ = precision_recall_curve(self.y_true, self.y_score)\n",
    "        plt.plot(recall, precision, marker='.')\n",
    "        plt.title('Precision-Recall Curve')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def auc_roc_curve(self):\n",
    "        fpr, tpr, _ = roc_curve(self.y_true, self.y_score)\n",
    "        auc_score = roc_auc_score(self.y_true, self.y_score)\n",
    "        plt.title('AUC-ROC Curve')\n",
    "        plt.xlabel('False Positive Rate (FPR)')\n",
    "        plt.ylabel('True Positive Rate (TPR)')\n",
    "        plt.plot(fpr, tpr, label=f'AUC = {auc_score:.4f}')\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def summary(self):\n",
    "        self.confusion_matrix()\n",
    "        self.accuracy()\n",
    "        self.precision()\n",
    "        self.recall()\n",
    "        self.f1_score()\n",
    "        self.kappa()\n",
    "        self.precision_recall_curve()\n",
    "        self.auc_roc_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c389af2e-e0cd-4e34-8bc5-65d6296af8c0",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# model = efficientnet_b0()\n",
    "# model.fc = torch.nn.Linear(model1.fc.in_features, 2)\n",
    "# model.load_state_dict(torch.load('/kaggle/input/efficientnetb0/pytorch/default/1/model1_full.pth'))\n",
    "model = torch.load(\"/kaggle/input/efficientnetb0/pytorch/default/1/model1_full.pth\")\n",
    "model_evaluator = ModelEvaluator(model=model, data_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4771515b-d245-4966-9b72-6f87a5379715",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_evaluator.summary()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5070657,
     "sourceId": 8497982,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 326239,
     "modelInstanceId": 305789,
     "sourceId": 369245,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
