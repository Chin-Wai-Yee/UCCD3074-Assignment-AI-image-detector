{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7598969,"sourceType":"datasetVersion","datasetId":4423404},{"sourceId":351134,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":293083,"modelId":313720}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"e9d01543-6a4e-4580-98ab-1f7af89ffd92","cell_type":"markdown","source":"# ASSIGNMENT 2","metadata":{}},{"id":"d6c43026-8e75-4adf-926b-91259d9ac884","cell_type":"markdown","source":"## Chin Wai Yee - Data Preprocessing","metadata":{}},{"id":"c758d8c1-11e6-44d7-b3d4-03e6e21f2ceb","cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"tristanzhang32/ai-generated-images-vs-real-images\")\n\nai_dir = path + \"/train/fake\"\nreal_dir = path + \"/train/real\"\n\n# Label 0 = AI-generated, Label 1 = Real\nai_data = [(os.path.join(ai_dir, f), 0) for f in os.listdir(ai_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\nreal_data = [(os.path.join(real_dir, f), 1) for f in os.listdir(real_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n\nfull_data = ai_data + real_data\nlabels = [label for _, label in full_data]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"6c94a32b-99b8-4c20-bf91-16475da6a68e","cell_type":"code","source":"# Train/val/test split\ntrain_val_data, test_data = train_test_split(full_data, test_size=0.15, stratify=labels, random_state=42)\ntrain_data, val_data = train_test_split(train_val_data, test_size=0.15, stratify=[label for _, label in train_val_data], random_state=42)\n\n# Custom Dataset\nclass ImagePathDataset(Dataset):\n    def __init__(self, data, transform=None):\n        self.data = data\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_path, label = self.data[idx]\n        try:\n            image = Image.open(img_path)\n    \n            if image.mode == 'P':\n                image = image.convert('RGBA')\n                background = Image.new(\"RGB\", image.size, (255, 255, 255))\n                image = Image.alpha_composite(background.convert('RGBA'), image).convert('RGB')\n            else:\n                image = image.convert('RGB')\n    \n            if self.transform:\n                image = self.transform(image)\n            return image, label\n    \n        except (OSError, IOError) as e:\n            print(f\"Skipping corrupted image: {img_path} ({str(e)})\")\n            return self.__getitem__((idx + 1) % len(self.data))  # Try next image","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"3ffa2f49-02a6-4823-b049-2660dae2d3bf","cell_type":"code","source":"# Data Augmentation for training\ntrain_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5]*3, [0.5]*3)\n])\n\n# Standard transform for val/test\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5]*3, [0.5]*3)\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"5aed2b12-9acf-496e-9ad3-8ccf3fa71dc8","cell_type":"code","source":"# Create datasets and loaders\ntrain_dataset = ImagePathDataset(train_data, transform=train_transform)\nval_dataset = ImagePathDataset(val_data, transform=test_transform)\ntest_dataset = ImagePathDataset(test_data, transform=test_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32)\ntest_loader = DataLoader(test_dataset, batch_size=32)","metadata":{},"outputs":[],"execution_count":null},{"id":"6a9b4133-6c70-425b-9a4d-ed9a06e7414e","cell_type":"markdown","source":"## Loh Kin Ming - Model, Hyperparameters & Training","metadata":{}},{"id":"b30ea76b-c0d0-4107-8667-eb6d1e62b19d","cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"id":"631099e1-24c0-41ff-b3ac-3d95e5e11afc","cell_type":"markdown","source":"## Brandon Ting En Junn - Evaluation & Demo","metadata":{}},{"id":"274a4980-aa43-4ddc-98f5-4e3e46724765","cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}