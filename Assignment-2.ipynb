{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8497982,"sourceType":"datasetVersion","datasetId":5070657},{"sourceId":369245,"sourceType":"modelInstanceVersion","modelInstanceId":305789,"modelId":326239}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"e9d01543-6a4e-4580-98ab-1f7af89ffd92","cell_type":"markdown","source":"# ASSIGNMENT 2","metadata":{}},{"id":"d6c43026-8e75-4adf-926b-91259d9ac884","cell_type":"markdown","source":"## Chin Wai Yee - Data Preprocessing","metadata":{}},{"id":"c758d8c1-11e6-44d7-b3d4-03e6e21f2ceb","cell_type":"code","source":"import os\nimport kagglehub\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\n\n# Download latest version\npath = kagglehub.dataset_download(\"tristanzhang32/ai-generated-images-vs-real-images\")\n\nai_dir = path + \"/train/fake\"\nreal_dir = path + \"/train/real\"\n\n# Label 0 = AI-generated, Label 1 = Real\nai_data = [(os.path.join(ai_dir, f), 0) for f in os.listdir(ai_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\nreal_data = [(os.path.join(real_dir, f), 1) for f in os.listdir(real_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n\nfull_data = ai_data + real_data\nlabels = [label for _, label in full_data]","metadata":{"execution":{"iopub.execute_input":"2025-05-02T09:07:10.686837Z","iopub.status.busy":"2025-05-02T09:07:10.686339Z","iopub.status.idle":"2025-05-02T09:07:20.799358Z","shell.execute_reply":"2025-05-02T09:07:20.798797Z","shell.execute_reply.started":"2025-05-02T09:07:10.686818Z"},"trusted":true},"outputs":[],"execution_count":1},{"id":"6c94a32b-99b8-4c20-bf91-16475da6a68e","cell_type":"code","source":"# Train/val/test split\ntrain_val_data, test_data = train_test_split(full_data, test_size=0.15, stratify=labels, random_state=42)\ntrain_data, val_data = train_test_split(train_val_data, test_size=0.15, stratify=[label for _, label in train_val_data], random_state=42)\n\n# Custom Dataset\nclass ImagePathDataset(Dataset):\n    def __init__(self, data, transform=None):\n        self.data = data\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_path, label = self.data[idx]\n        try:\n            image = Image.open(img_path)\n    \n            if image.mode == 'P':\n                image = image.convert('RGBA')\n                background = Image.new(\"RGB\", image.size, (255, 255, 255))\n                image = Image.alpha_composite(background.convert('RGBA'), image).convert('RGB')\n            else:\n                image = image.convert('RGB')\n    \n            if self.transform:\n                image = self.transform(image)\n            return image, label\n    \n        except (OSError, IOError) as e:\n            print(f\"Skipping corrupted image: {img_path} ({str(e)})\")\n            return self.__getitem__((idx + 1) % len(self.data))  # Try next image","metadata":{"execution":{"iopub.execute_input":"2025-05-02T09:07:20.800455Z","iopub.status.busy":"2025-05-02T09:07:20.800057Z","iopub.status.idle":"2025-05-02T09:07:20.857711Z","shell.execute_reply":"2025-05-02T09:07:20.857031Z","shell.execute_reply.started":"2025-05-02T09:07:20.800434Z"},"trusted":true},"outputs":[],"execution_count":2},{"id":"3ffa2f49-02a6-4823-b049-2660dae2d3bf","cell_type":"code","source":"# Data Augmentation for training\ntrain_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5]*3, [0.5]*3)\n])\n\n# Standard transform for val/test\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5]*3, [0.5]*3)\n])","metadata":{"execution":{"iopub.execute_input":"2025-05-02T09:07:20.859370Z","iopub.status.busy":"2025-05-02T09:07:20.859167Z","iopub.status.idle":"2025-05-02T09:07:20.864439Z","shell.execute_reply":"2025-05-02T09:07:20.863749Z","shell.execute_reply.started":"2025-05-02T09:07:20.859355Z"},"trusted":true},"outputs":[],"execution_count":3},{"id":"5aed2b12-9acf-496e-9ad3-8ccf3fa71dc8","cell_type":"code","source":"# Create datasets and loaders\ntrain_dataset = ImagePathDataset(train_data, transform=train_transform)\nval_dataset = ImagePathDataset(val_data, transform=test_transform)\ntest_dataset = ImagePathDataset(test_data, transform=test_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32)\ntest_loader = DataLoader(test_dataset, batch_size=32)","metadata":{"execution":{"iopub.execute_input":"2025-05-02T09:07:20.865339Z","iopub.status.busy":"2025-05-02T09:07:20.865089Z","iopub.status.idle":"2025-05-02T09:07:20.884308Z","shell.execute_reply":"2025-05-02T09:07:20.883729Z","shell.execute_reply.started":"2025-05-02T09:07:20.865317Z"},"trusted":true},"outputs":[],"execution_count":4},{"id":"6a9b4133-6c70-425b-9a4d-ed9a06e7414e","cell_type":"markdown","source":"## Loh Kin Ming - Model, Hyperparameters & Training","metadata":{}},{"id":"b30ea76b-c0d0-4107-8667-eb6d1e62b19d","cell_type":"code","source":"import torch\nfrom PIL import Image\nimport timm\nimport torch.nn as nn\nimport torch.optim as optim\nfrom tqdm import tqdm","metadata":{},"outputs":[],"execution_count":null},{"id":"dfff48c0","cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nmodel = timm.create_model('efficientnet_b0', pretrained=True, num_classes=2)\nmodel = model.to(device)","metadata":{},"outputs":[],"execution_count":null},{"id":"7da830c3","cell_type":"code","source":"## To Freeze Layers\n## Uncomment below to run\n# Freeze all layers\n# for param in model.parameters():\n#     param.requires_grad = False\n\n# # Unfreeze only the classifier\n# for param in model.classifier.parameters():\n#     param.requires_grad = True","metadata":{},"outputs":[],"execution_count":null},{"id":"8890c964","cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)","metadata":{},"outputs":[],"execution_count":null},{"id":"e8adaa57","cell_type":"code","source":"def train(model, train_loader, val_loader, epochs=10):\n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0\n        correct, total = 0, 0\n        \n        for images, labels in tqdm(train_loader):\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            \n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n\n        acc = correct / total * 100\n        print(f\"Epoch {epoch+1}: Loss={running_loss:.4f}, Accuracy={acc:.2f}%\")\n\n        # Evaluate on validation set\n        evaluate(model, val_loader, \"Validation\")\n\ndef evaluate(model, loader, name=\"Test\"):\n    model.eval()\n    correct, total = 0, 0\n    with torch.no_grad():\n        for images, labels in loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n\n    print(f\"{name} Accuracy: {correct / total * 100:.2f}%\")","metadata":{},"outputs":[],"execution_count":null},{"id":"795d55be","cell_type":"code","source":"train(model, train_loader, val_loader, epochs=5)\nevaluate(model, test_loader)","metadata":{},"outputs":[],"execution_count":null},{"id":"631099e1-24c0-41ff-b3ac-3d95e5e11afc","cell_type":"markdown","source":"## Brandon Ting En Junn - Evaluation & Demo","metadata":{}},{"id":"2dfce766-f5f0-4719-9ad0-6e5a6edf7fe1","cell_type":"code","source":"import torch\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom torchvision.models import efficientnet_b0\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve, roc_auc_score, roc_curve, cohen_kappa_score","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"4a117d39-d8ed-4f17-ba0c-5eff48f796df","cell_type":"code","source":"class ModelEvaluator():\n    def __init__(self, model, data_loader):\n        self.model = model\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.y_true = []\n        self.y_pred = []\n        self.y_score = []\n\n        self.model.eval()\n        self.model.to(self.device)\n\n        print(\"Running Evaluation...\")\n        with torch.no_grad():\n            for inputs, labels in data_loader:\n                inputs, labels = inputs.to(self.device), labels.to(self.device)\n\n                outputs = self.model(inputs)\n\n                probits = torch.softmax(outputs, dim=1)\n\n                _, pred = torch.max(probits, dim=1)\n\n                self.y_true.extend(labels.to(\"cpu\").numpy())\n                self.y_pred.extend(pred.to(\"cpu\").numpy())\n                self.y_score.extend(probits[:, 1].to(\"cpu\").numpy())\n        print(\"Finished Evaluation...\")\n\n    def confusion_matrix(self):\n        sns.heatmap(confusion_matrix(self.y_true, self.y_pred), annot=True)\n        plt.title(\"Confusion Matrix\")\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Actual\")\n        plt.show()\n\n    def accuracy(self):\n        print(f\"Accuracy: {accuracy_score(self.y_true, self.y_pred)}\")\n\n    def precision(self):\n        print(f\"Precision: {precision_score(self.y_true, self.y_pred)}\")\n\n    def recall(self):\n        print(f\"Recall: {recall_score(self.y_true, self.y_pred)}\")\n\n    def f1_score(self):\n        print(f\"F1-Score: {f1_score(self.y_true, self.y_pred)}\")\n\n    def kappa(self):\n        print(f\"Kappa Coefficient: {cohen_kappa_score(self.y_true, self.y_pred)}\")\n\n    def precision_recall_curve(self):\n        precision, recall, _ = precision_recall_curve(self.y_true, self.y_score)\n        plt.plot(recall, precision, marker='.')\n        plt.title('Precision-Recall Curve')\n        plt.xlabel('Recall')\n        plt.ylabel('Precision')\n        plt.grid(True)\n        plt.show()\n\n    def auc_roc_curve(self):\n        fpr, tpr, _ = roc_curve(self.y_true, self.y_score)\n        auc_score = roc_auc_score(self.y_true, self.y_score)\n        plt.title('AUC-ROC Curve')\n        plt.xlabel('False Positive Rate (FPR)')\n        plt.ylabel('True Positive Rate (TPR)')\n        plt.plot(fpr, tpr, label=f'AUC = {auc_score:.4f}')\n        plt.plot([0, 1], [0, 1], linestyle='--')\n        plt.grid(True)\n        plt.legend()\n        plt.show()\n\n    def summary(self):\n        self.confusion_matrix()\n        self.accuracy()\n        self.precision()\n        self.recall()\n        self.f1_score()\n        self.kappa()\n        self.precision_recall_curve()\n        self.auc_roc_curve()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c389af2e-e0cd-4e34-8bc5-65d6296af8c0","cell_type":"code","source":"# model = efficientnet_b0()\n# model.fc = torch.nn.Linear(model1.fc.in_features, 2)\n# model.load_state_dict(torch.load('/kaggle/input/efficientnetb0/pytorch/default/1/model1_full.pth'))\nmodel = torch.load(\"/kaggle/input/efficientnetb0/pytorch/default/1/model1_full.pth\")\nmodel_evaluator = ModelEvaluator(model=model, data_loader=test_loader)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"4771515b-d245-4966-9b72-6f87a5379715","cell_type":"code","source":"model_evaluator.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}